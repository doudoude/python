# -*- coding: utf-8 -*-
"""
Created on Tue Apr 23 09:40:07 2019

@author: Administrator
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn import preprocessing
import gc
from sklearn.preprocessing import StandardScaler



df=pd.read_csv("E:/OneConnect_DS_Challenge/data/CR_Data.csv")
original_df=df.copy()
df.head()
df.shape           #(187496, 93)

#check the null
df.isnull().values.any()    #True
col=df.isnull().any(axis=0) 
col1=col[col.values==True]  
col1

"""
select the feature:
    loan_amnt
    int_rate
    grade
    emp_length
    loan_status
    home_ownership
    annual_inc
    term
"""

#emp_length
df[df['emp_length'].isnull()==True].shape   #13933 null, delete rows
df=df.dropna(subset=['emp_length'])
df.shape                      #(173563, 8)
df.emp_length.isnull().any()    #false
df['emp_length'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)
df.emp_length

feature_names=['loan_amnt' , 'int_rate', 'grade' , 'emp_length',
        'home_ownership' , 'annual_inc','term']
df = df[['loan_status','loan_amnt' , 'int_rate', 'grade' , 'emp_length',
        'home_ownership' , 'annual_inc','term']]

#encoding
count = 0
for col in df:
    if df[col].dtype == 'object':
        if len(list(df[col].unique())) <= 2:     
            le = preprocessing.LabelEncoder()
            df[col] = le.fit_transform(df[col])
            count += 1
            print (col)
            
print('%d columns were label encoded.' % count)

df = pd.get_dummies(df)
print(df.shape) #173563 rows x 27 columns]
#df[['loan_status']]   1:fully paid 0:charged off

x_loan=df.drop('loan_status',axis=1)
#standerdize features
sc = StandardScaler()
x_loan = sc.fit_transform(x_loan)



#PCA 降维
import sklearn.decomposition as sk_decomposition
pca = sk_decomposition.PCA(n_components=7,whiten=False,svd_solver='auto')
pca.fit(x_loan)
reduced_x = pca.transform(x_loan) #reduced_X为降维后的数据
reduced_x.shape
reduced_x

y_loan=df['loan_status']
x_train1, x_test1, y_train1, y_test1 = train_test_split(reduced_x,y_loan, random_state=0)

#free up the memory
del original_df
gc.collect()


"""#oversampling
from imblearn.over_sampling import SMOTE  #无法安装
sm = SMOTE(random_state=12, ratio = 1.0)
x_train_r, y_train_r = sm.fit_sample(x_train, y_train)
"""
#logistic regression
log_reg = LogisticRegression(C = 1,random_state=21,class_weight='balanced')
log_reg.fit(x_train1, y_train1)


#model score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score, cross_val_predict
def print_score(clf, X_train, y_train, X_test, y_test, train=True):
    if train:
        print("Train Result:\n")
        print("accuracy score: {0:.4f}\n".format(accuracy_score(y_train, clf.predict(X_train))))
        print("Classification Report: \n {}\n".format(classification_report(y_train, clf.predict(X_train))))
        print("Confusion Matrix: \n {}\n".format(confusion_matrix(y_train, clf.predict(X_train))))

        res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')
        print("Average Accuracy: \t {0:.4f}".format(np.mean(res)))
        print("Accuracy SD: \t\t {0:.4f}".format(np.std(res)))
        
    elif train==False:
        print("Test Result:\n")        
        print("accuracy score: {0:.4f}\n".format(accuracy_score(y_test, clf.predict(X_test))))
        print("Classification Report: \n {}\n".format(classification_report(y_test, clf.predict(X_test))))
        print("Confusion Matrix: \n {}\n".format(confusion_matrix(y_test, clf.predict(X_test))))  

print_score(log_reg, x_train1, y_train1, x_test1, y_test1, train=False)

"""
                modelN modelP
true negative      [TN FP      tyer 1 error:false positive
true positive       FN TP]        type 2 error:false negative
recall=TP/(TP+FN)
precision=TP/(TP+FP)
F1 score =2TP/(2TP+FN+FP)
support: #of test that have true label
"""


